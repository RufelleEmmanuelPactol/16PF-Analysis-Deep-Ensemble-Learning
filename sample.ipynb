{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:22.076994Z",
     "start_time": "2024-08-02T05:10:22.071532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "class TagHolder:\n",
    "\n",
    "    def __init__(self, _id, name):\n",
    "        self.id = _id\n",
    "        self.name = name\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "\n",
    "def get_tags():\n",
    "    connection = get_engine()\n",
    "    if not connection:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT * from datasetTag\")\n",
    "            tags = cursor.fetchall()\n",
    "\n",
    "            tag_holder = []\n",
    "            for tag in tags:\n",
    "                tag_holder.append(TagHolder(tag[0], tag[1]))\n",
    "\n",
    "            return tag_holder\n",
    "    except Exception as e:\n",
    "        return []\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            connection.close()\n",
    "            \n",
    "            \n",
    "from typing import Union\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector.abstracts import MySQLConnectionAbstract\n",
    "from mysql.connector.pooling import PooledMySQLConnection\n",
    "\n",
    "def get_engine():\n",
    "    # Create a MySQL connection using mysql.connector\n",
    "    connection = mysql.connector.connect(\n",
    "        host='monorail.proxy.rlwy.net',\n",
    "        port=45826,\n",
    "        user='root',\n",
    "        password='VoUeejgBIkMgYiPmYHxMFsIXffwxCKBK',\n",
    "        database='railway'\n",
    "    )\n",
    "    return connection\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "107a5dc01c0526fd",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:22.166333Z",
     "start_time": "2024-08-02T05:10:22.164966Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d8b372c77182191c",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:22.188961Z",
     "start_time": "2024-08-02T05:10:22.187652Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "37e64e9508b6424",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:22.207667Z",
     "start_time": "2024-08-02T05:10:22.206038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def discretize_weights(weight):\n",
    "    if weight < 50:\n",
    "        return 0\n",
    "    if 50 <= weight < 85:\n",
    "        return 1\n",
    "    if 85 <= weight <= 100:\n",
    "        return 2"
   ],
   "id": "3148aa8e29e2240c",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:22.226333Z",
     "start_time": "2024-08-02T05:10:22.224050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_data_as_dataframe(connection, query: str) -> pd.DataFrame:\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    result_set = cursor.fetchall()\n",
    "    column_names = cursor.column_names\n",
    "    cursor.close()\n",
    "    df = pd.DataFrame(result_set, columns=column_names)\n",
    "    return df.dropna()"
   ],
   "id": "62d50ecc8c69f78a",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:22.239169Z",
     "start_time": "2024-08-02T05:10:22.236902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def discretize_weights(weight):\n",
    "    if weight < 50:\n",
    "        return 0\n",
    "    if 50 <= weight < 95:\n",
    "        return 1\n",
    "    if 85 <= weight <= 100:\n",
    "        return 2"
   ],
   "id": "67b7878a0b6feb75",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:22.252646Z",
     "start_time": "2024-08-02T05:10:22.251460Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b7c9b0af3ce9b90c",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:22.269589Z",
     "start_time": "2024-08-02T05:10:22.268350Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5a0892d81227b581",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:25.725878Z",
     "start_time": "2024-08-02T05:10:22.283268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = f\"\"\"\n",
    "                        SELECT ((grade-1)/4)*100 as weighted, attr_A, attr_B, attr_C, attr_E, attr_F, attr_H, attr_G, attr_I, attr_L, attr_M, attr_N, attr_O, attr_Q1, attr_Q2,\n",
    "                                attr_Q3, attr_Q4, attr_EX, attr_AX, attr_TM, attr_IN, attr_SC,\n",
    "                                cfit,\n",
    "                                CASE when course = 'BSCS' then 1 else 0 end as course_bscs,\n",
    "                                CASE when course = 'BSIT' then 1 else 0 end as course_bsit\n",
    "                        FROM students\n",
    "                        INNER JOIN assessments s on s.student_id = students.Id WHERE tagID in (5);\n",
    "                        \"\"\"\n",
    "df = fetch_data_as_dataframe(get_engine(), query)\n",
    "df = pd.get_dummies(df, columns=['cfit'])\n",
    "df.dropna(inplace=True)"
   ],
   "id": "a822fb37ee7f0e43",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:25.730317Z",
     "start_time": "2024-08-02T05:10:25.727855Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d444d19e30e1eb8",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:25.743971Z",
     "start_time": "2024-08-02T05:10:25.731687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_y = df['weighted'].apply(discretize_weights)\n",
    "df.head()"
   ],
   "id": "aa3fc8d4d319d49c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    weighted  attr_A  attr_B  attr_C  attr_E  attr_F  attr_H  attr_G  attr_I  \\\n",
       "0   0.000000       4       4       5       3       5       4       6       5   \n",
       "1  60.000002       5       6       7       1       5       6       5       7   \n",
       "2  57.499999       2       5       6       4       1       2       7       4   \n",
       "3  64.999998       5       6       5       4       7       6       6       7   \n",
       "4   0.000000       6       4       3       1       4       2       7       8   \n",
       "\n",
       "   attr_L  ...  attr_IN  attr_SC  course_bscs  course_bsit  cfit_A  cfit_AA  \\\n",
       "0       7  ...        4        5            1            0   False    False   \n",
       "1       5  ...        3        6            1            0   False     True   \n",
       "2       7  ...        4        7            1            0    True    False   \n",
       "3       9  ...        4        6            1            0   False     True   \n",
       "4       5  ...        1        6            1            0   False    False   \n",
       "\n",
       "   cfit_BA  cfit_H  cfit_L  cfit_M  \n",
       "0    False   False    True   False  \n",
       "1    False   False   False   False  \n",
       "2    False   False   False   False  \n",
       "3    False   False   False   False  \n",
       "4     True   False   False   False  \n",
       "\n",
       "[5 rows x 30 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted</th>\n",
       "      <th>attr_A</th>\n",
       "      <th>attr_B</th>\n",
       "      <th>attr_C</th>\n",
       "      <th>attr_E</th>\n",
       "      <th>attr_F</th>\n",
       "      <th>attr_H</th>\n",
       "      <th>attr_G</th>\n",
       "      <th>attr_I</th>\n",
       "      <th>attr_L</th>\n",
       "      <th>...</th>\n",
       "      <th>attr_IN</th>\n",
       "      <th>attr_SC</th>\n",
       "      <th>course_bscs</th>\n",
       "      <th>course_bsit</th>\n",
       "      <th>cfit_A</th>\n",
       "      <th>cfit_AA</th>\n",
       "      <th>cfit_BA</th>\n",
       "      <th>cfit_H</th>\n",
       "      <th>cfit_L</th>\n",
       "      <th>cfit_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.000002</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.499999</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.999998</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:25.751233Z",
     "start_time": "2024-08-02T05:10:25.745988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['weighted']), df['weighted'], test_size=0.2)"
   ],
   "id": "c2ac86745292cf52",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:25.753871Z",
     "start_time": "2024-08-02T05:10:25.752294Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "af61b950d0c42ca8",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:25.765322Z",
     "start_time": "2024-08-02T05:10:25.754675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# success classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "success_y = df['weighted'].apply(discretize_weights).apply(lambda x: x==2)\n",
    "x_s, y_s = smote.fit_resample(df.drop(columns=['weighted']), success_y)\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(x_s, y_s, test_size=0.2)"
   ],
   "id": "684ff16fd6a6f1d",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:25.767715Z",
     "start_time": "2024-08-02T05:10:25.766195Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "32a1481f22dc986",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:25.771327Z",
     "start_time": "2024-08-02T05:10:25.768345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_df = df.copy()\n",
    "final_df_features = np.asarray(final_df.drop(columns=['weighted']), np.float64)"
   ],
   "id": "68f8d99ef0ff8097",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:27.789362Z",
     "start_time": "2024-08-02T05:10:25.772065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert data types\n",
    "X_train_s = np.asarray(X_train_s).astype(np.float64)\n",
    "y_train_s = np.asarray(y_train_s).astype(np.int16)\n",
    "X_test_s = np.asarray(X_test_s).astype(np.float64)\n",
    "y_test_s = np.asarray(y_test_s).astype(np.int16)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential([\n",
    "    InputLayer(shape=(X_train_s.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Single output unit for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_s, y_train_s, epochs=30, batch_size=32, validation_split=0.2, verbose=1, )\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_s)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to class labels\n",
    "final_df['success'] = model.predict(final_df_features)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_s, y_pred)\n",
    "f'Accuracy: {accuracy}'"
   ],
   "id": "1c9ee196640447f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.5208 - loss: 0.6932 - val_accuracy: 0.6200 - val_loss: 0.6362\n",
      "Epoch 2/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7396 - loss: 0.5285 - val_accuracy: 0.8933 - val_loss: 0.3122\n",
      "Epoch 3/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8581 - loss: 0.3315 - val_accuracy: 0.8267 - val_loss: 0.4414\n",
      "Epoch 4/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8806 - loss: 0.2691 - val_accuracy: 0.9733 - val_loss: 0.1477\n",
      "Epoch 5/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8928 - loss: 0.2678 - val_accuracy: 0.9267 - val_loss: 0.1841\n",
      "Epoch 6/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9473 - loss: 0.1475 - val_accuracy: 0.9467 - val_loss: 0.1316\n",
      "Epoch 7/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9430 - loss: 0.1715 - val_accuracy: 0.9667 - val_loss: 0.0878\n",
      "Epoch 8/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9845 - loss: 0.0630 - val_accuracy: 0.9600 - val_loss: 0.1192\n",
      "Epoch 9/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9770 - loss: 0.1109 - val_accuracy: 0.9733 - val_loss: 0.0783\n",
      "Epoch 10/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9565 - loss: 0.1241 - val_accuracy: 0.9200 - val_loss: 0.2048\n",
      "Epoch 11/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9593 - loss: 0.1072 - val_accuracy: 0.9867 - val_loss: 0.0621\n",
      "Epoch 12/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9829 - loss: 0.0392 - val_accuracy: 0.9667 - val_loss: 0.1678\n",
      "Epoch 13/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9755 - loss: 0.0850 - val_accuracy: 0.9933 - val_loss: 0.0776\n",
      "Epoch 14/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9916 - loss: 0.0249 - val_accuracy: 0.9733 - val_loss: 0.1039\n",
      "Epoch 15/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9830 - loss: 0.0937 - val_accuracy: 0.9867 - val_loss: 0.0829\n",
      "Epoch 16/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9835 - loss: 0.0831 - val_accuracy: 0.9933 - val_loss: 0.0547\n",
      "Epoch 17/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9977 - loss: 0.0199 - val_accuracy: 0.9933 - val_loss: 0.0639\n",
      "Epoch 18/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9982 - loss: 0.0122 - val_accuracy: 0.9933 - val_loss: 0.0643\n",
      "Epoch 19/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9993 - loss: 0.0062 - val_accuracy: 0.9933 - val_loss: 0.0580\n",
      "Epoch 20/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9936 - loss: 0.0116 - val_accuracy: 0.9800 - val_loss: 0.0754\n",
      "Epoch 21/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9933 - val_loss: 0.0648\n",
      "Epoch 22/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 4.9148e-04 - val_accuracy: 0.9933 - val_loss: 0.0718\n",
      "Epoch 23/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 1.0000 - loss: 1.3681e-04 - val_accuracy: 0.9933 - val_loss: 0.0804\n",
      "Epoch 24/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 1.0000 - loss: 4.8200e-05 - val_accuracy: 0.9933 - val_loss: 0.0871\n",
      "Epoch 25/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 3.0480e-05 - val_accuracy: 0.9933 - val_loss: 0.1022\n",
      "Epoch 26/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 9.9647e-06 - val_accuracy: 0.9867 - val_loss: 0.1128\n",
      "Epoch 27/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 5.5277e-06 - val_accuracy: 0.9933 - val_loss: 0.1124\n",
      "Epoch 28/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 1.0000 - loss: 2.9331e-06 - val_accuracy: 0.9867 - val_loss: 0.1227\n",
      "Epoch 29/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 1.0000 - loss: 2.5787e-06 - val_accuracy: 0.9933 - val_loss: 0.1194\n",
      "Epoch 30/30\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 1.0000 - loss: 1.7841e-06 - val_accuracy: 0.9867 - val_loss: 0.1284\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step \n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 431us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.9840425531914894'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:27.793646Z",
     "start_time": "2024-08-02T05:10:27.791246Z"
    }
   },
   "cell_type": "code",
   "source": "final_df['success']",
   "id": "52c412ae4ba949bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.210673e-09\n",
       "1      5.100537e-10\n",
       "2      9.249924e-18\n",
       "3      3.563413e-20\n",
       "4      1.651953e-19\n",
       "           ...     \n",
       "473    2.493636e-22\n",
       "474    3.318062e-19\n",
       "475    2.226829e-16\n",
       "476    5.163840e-25\n",
       "477    1.539102e-21\n",
       "Name: success, Length: 478, dtype: float32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:27.798972Z",
     "start_time": "2024-08-02T05:10:27.794310Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "75877ab4b77ddc94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    weighted  attr_A  attr_B  attr_C  attr_E  attr_F  attr_H  attr_G  attr_I  \\\n",
       "0   0.000000       4       4       5       3       5       4       6       5   \n",
       "1  60.000002       5       6       7       1       5       6       5       7   \n",
       "2  57.499999       2       5       6       4       1       2       7       4   \n",
       "3  64.999998       5       6       5       4       7       6       6       7   \n",
       "4   0.000000       6       4       3       1       4       2       7       8   \n",
       "\n",
       "   attr_L  ...  attr_IN  attr_SC  course_bscs  course_bsit  cfit_A  cfit_AA  \\\n",
       "0       7  ...        4        5            1            0   False    False   \n",
       "1       5  ...        3        6            1            0   False     True   \n",
       "2       7  ...        4        7            1            0    True    False   \n",
       "3       9  ...        4        6            1            0   False     True   \n",
       "4       5  ...        1        6            1            0   False    False   \n",
       "\n",
       "   cfit_BA  cfit_H  cfit_L  cfit_M  \n",
       "0    False   False    True   False  \n",
       "1    False   False   False   False  \n",
       "2    False   False   False   False  \n",
       "3    False   False   False   False  \n",
       "4     True   False   False   False  \n",
       "\n",
       "[5 rows x 30 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted</th>\n",
       "      <th>attr_A</th>\n",
       "      <th>attr_B</th>\n",
       "      <th>attr_C</th>\n",
       "      <th>attr_E</th>\n",
       "      <th>attr_F</th>\n",
       "      <th>attr_H</th>\n",
       "      <th>attr_G</th>\n",
       "      <th>attr_I</th>\n",
       "      <th>attr_L</th>\n",
       "      <th>...</th>\n",
       "      <th>attr_IN</th>\n",
       "      <th>attr_SC</th>\n",
       "      <th>course_bscs</th>\n",
       "      <th>course_bsit</th>\n",
       "      <th>cfit_A</th>\n",
       "      <th>cfit_AA</th>\n",
       "      <th>cfit_BA</th>\n",
       "      <th>cfit_H</th>\n",
       "      <th>cfit_L</th>\n",
       "      <th>cfit_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.000002</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.499999</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.999998</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:27.800708Z",
     "start_time": "2024-08-02T05:10:27.799649Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ada4b46acc8467ee",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ed37739170c7b430"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:27.802389Z",
     "start_time": "2024-08-02T05:10:27.801109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ],
   "id": "d01fc50172f908a3",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:29.648650Z",
     "start_time": "2024-08-02T05:10:27.802854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# success classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "success_y = df['weighted'].apply(discretize_weights).apply(lambda x: x==0)\n",
    "smote = SMOTE()\n",
    "x_f, y_f = smote.fit_resample(df.drop(columns=['weighted']), success_y)\n",
    "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(x_f, y_f, test_size=0.2)\n",
    "from keras.src.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert data types\n",
    "X_train_f = np.asarray(X_train_f).astype(np.float64)\n",
    "y_train_f = np.asarray(y_train_f).astype(np.int16)\n",
    "X_test_f = np.asarray(X_test_f).astype(np.float64)\n",
    "y_test_f = np.asarray(y_test_f).astype(np.int16)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential([\n",
    "    InputLayer(shape=(X_train_s.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Single output unit for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_f, y_train_f, epochs=30, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_f)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to class labels\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_f, y_pred)\n",
    "\n",
    "f'Accuracy: {accuracy}'"
   ],
   "id": "a4ff1c0c53927b60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.4991 - loss: 0.6943 - val_accuracy: 0.4516 - val_loss: 0.6926\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.4973 - loss: 0.6920 - val_accuracy: 0.4919 - val_loss: 0.6774\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5986 - loss: 0.6594 - val_accuracy: 0.6935 - val_loss: 0.5972\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.6913 - loss: 0.6093 - val_accuracy: 0.6855 - val_loss: 0.6057\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7121 - loss: 0.5606 - val_accuracy: 0.7581 - val_loss: 0.5239\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7664 - loss: 0.4788 - val_accuracy: 0.7258 - val_loss: 0.5416\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8205 - loss: 0.4259 - val_accuracy: 0.8226 - val_loss: 0.4403\n",
      "Epoch 8/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8477 - loss: 0.4065 - val_accuracy: 0.7823 - val_loss: 0.4592\n",
      "Epoch 9/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8066 - loss: 0.3692 - val_accuracy: 0.7097 - val_loss: 0.5300\n",
      "Epoch 10/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8222 - loss: 0.4024 - val_accuracy: 0.7339 - val_loss: 0.5739\n",
      "Epoch 11/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8383 - loss: 0.3559 - val_accuracy: 0.7661 - val_loss: 0.5044\n",
      "Epoch 12/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8537 - loss: 0.3143 - val_accuracy: 0.7339 - val_loss: 0.5368\n",
      "Epoch 13/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9003 - loss: 0.2623 - val_accuracy: 0.8710 - val_loss: 0.3907\n",
      "Epoch 14/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8941 - loss: 0.2750 - val_accuracy: 0.7742 - val_loss: 0.4437\n",
      "Epoch 15/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9064 - loss: 0.2368 - val_accuracy: 0.8226 - val_loss: 0.6477\n",
      "Epoch 16/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9010 - loss: 0.2549 - val_accuracy: 0.8306 - val_loss: 0.4132\n",
      "Epoch 17/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9294 - loss: 0.1737 - val_accuracy: 0.8468 - val_loss: 0.4338\n",
      "Epoch 18/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9430 - loss: 0.1298 - val_accuracy: 0.8306 - val_loss: 0.4576\n",
      "Epoch 19/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9456 - loss: 0.1245 - val_accuracy: 0.8629 - val_loss: 0.3931\n",
      "Epoch 20/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9593 - loss: 0.1092 - val_accuracy: 0.8710 - val_loss: 0.4721\n",
      "Epoch 21/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9226 - loss: 0.2207 - val_accuracy: 0.8468 - val_loss: 0.4317\n",
      "Epoch 22/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9404 - loss: 0.1505 - val_accuracy: 0.8468 - val_loss: 0.3996\n",
      "Epoch 23/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9521 - loss: 0.1507 - val_accuracy: 0.8065 - val_loss: 0.4620\n",
      "Epoch 24/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9556 - loss: 0.1476 - val_accuracy: 0.7661 - val_loss: 0.7255\n",
      "Epoch 25/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9383 - loss: 0.1621 - val_accuracy: 0.8710 - val_loss: 0.3577\n",
      "Epoch 26/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9455 - loss: 0.1179 - val_accuracy: 0.8629 - val_loss: 0.3841\n",
      "Epoch 27/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9860 - loss: 0.0658 - val_accuracy: 0.8710 - val_loss: 0.5336\n",
      "Epoch 28/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9802 - loss: 0.0634 - val_accuracy: 0.8387 - val_loss: 0.5296\n",
      "Epoch 29/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9325 - loss: 0.1412 - val_accuracy: 0.8065 - val_loss: 0.7456\n",
      "Epoch 30/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9455 - loss: 0.1310 - val_accuracy: 0.8548 - val_loss: 0.3314\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.8774193548387097'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:29.672258Z",
     "start_time": "2024-08-02T05:10:29.649208Z"
    }
   },
   "cell_type": "code",
   "source": "model.predict(X_test_f)",
   "id": "8ee9dc3b59f69e61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 511us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.5423923e-01],\n",
       "       [7.4791950e-01],\n",
       "       [7.2102457e-02],\n",
       "       [5.0588393e-01],\n",
       "       [2.0435487e-01],\n",
       "       [9.8909944e-01],\n",
       "       [1.6512875e-01],\n",
       "       [9.0861762e-01],\n",
       "       [9.8315251e-01],\n",
       "       [4.7380516e-01],\n",
       "       [4.0790934e-02],\n",
       "       [1.5984176e-02],\n",
       "       [9.9997431e-01],\n",
       "       [2.3534641e-01],\n",
       "       [3.3130821e-02],\n",
       "       [8.9954859e-01],\n",
       "       [2.8571910e-01],\n",
       "       [8.3596945e-01],\n",
       "       [2.1064974e-01],\n",
       "       [4.9152400e-02],\n",
       "       [7.1566072e-05],\n",
       "       [5.0732934e-01],\n",
       "       [3.7646151e-01],\n",
       "       [8.6651576e-01],\n",
       "       [9.9656636e-01],\n",
       "       [5.0785784e-02],\n",
       "       [9.1364908e-01],\n",
       "       [7.7267343e-01],\n",
       "       [1.1730728e-03],\n",
       "       [8.5731989e-01],\n",
       "       [9.0538979e-01],\n",
       "       [6.6513062e-01],\n",
       "       [9.8844671e-01],\n",
       "       [4.9823260e-01],\n",
       "       [9.5919144e-01],\n",
       "       [3.2348987e-01],\n",
       "       [2.7368451e-02],\n",
       "       [9.9982673e-01],\n",
       "       [7.9853777e-03],\n",
       "       [9.8301989e-01],\n",
       "       [5.0751655e-03],\n",
       "       [3.9841732e-01],\n",
       "       [2.4640067e-06],\n",
       "       [1.9080217e-01],\n",
       "       [9.7829765e-01],\n",
       "       [8.8454497e-01],\n",
       "       [9.6828258e-01],\n",
       "       [1.4567918e-01],\n",
       "       [9.9404961e-01],\n",
       "       [1.1322570e-01],\n",
       "       [3.4215266e-03],\n",
       "       [8.4095770e-01],\n",
       "       [7.2848350e-01],\n",
       "       [6.1535174e-01],\n",
       "       [1.5595628e-01],\n",
       "       [2.6693954e-03],\n",
       "       [9.4225371e-01],\n",
       "       [3.5161335e-02],\n",
       "       [9.9853021e-01],\n",
       "       [9.9678499e-01],\n",
       "       [2.3177311e-02],\n",
       "       [9.9980187e-01],\n",
       "       [2.1627843e-03],\n",
       "       [4.1072833e-04],\n",
       "       [1.9970834e-01],\n",
       "       [2.1245803e-03],\n",
       "       [9.6440343e-03],\n",
       "       [7.8685057e-01],\n",
       "       [4.2869228e-01],\n",
       "       [1.9930331e-02],\n",
       "       [9.2788613e-01],\n",
       "       [4.9770754e-03],\n",
       "       [1.0311675e-01],\n",
       "       [3.3723700e-01],\n",
       "       [1.8405657e-02],\n",
       "       [4.2679298e-04],\n",
       "       [4.2753797e-03],\n",
       "       [6.7797780e-01],\n",
       "       [9.5551306e-01],\n",
       "       [1.5705120e-02],\n",
       "       [7.2834557e-01],\n",
       "       [9.3063885e-01],\n",
       "       [9.9485505e-01],\n",
       "       [6.9364405e-01],\n",
       "       [3.0819562e-01],\n",
       "       [5.8972573e-01],\n",
       "       [9.7430271e-01],\n",
       "       [9.3156676e-05],\n",
       "       [5.4066800e-02],\n",
       "       [6.3075416e-02],\n",
       "       [9.9051040e-01],\n",
       "       [9.6101445e-01],\n",
       "       [8.1041318e-01],\n",
       "       [1.8854964e-01],\n",
       "       [7.6947141e-01],\n",
       "       [9.9578321e-01],\n",
       "       [5.0490454e-02],\n",
       "       [2.1290027e-02],\n",
       "       [9.9862087e-01],\n",
       "       [4.5425102e-02],\n",
       "       [1.6280501e-01],\n",
       "       [1.0673236e-01],\n",
       "       [3.9550933e-01],\n",
       "       [2.0026125e-01],\n",
       "       [9.9445397e-01],\n",
       "       [2.8495661e-03],\n",
       "       [9.5854199e-01],\n",
       "       [9.7490460e-01],\n",
       "       [1.3579783e-01],\n",
       "       [9.6315157e-01],\n",
       "       [1.2213842e-03],\n",
       "       [2.5067931e-01],\n",
       "       [1.3117231e-01],\n",
       "       [7.2401454e-06],\n",
       "       [2.6732740e-01],\n",
       "       [9.7948635e-01],\n",
       "       [1.1117166e-02],\n",
       "       [9.9733210e-01],\n",
       "       [2.7932074e-02],\n",
       "       [1.7863427e-01],\n",
       "       [8.1052236e-02],\n",
       "       [3.2628044e-01],\n",
       "       [9.6509981e-01],\n",
       "       [9.2031293e-02],\n",
       "       [9.7342506e-03],\n",
       "       [8.5203207e-01],\n",
       "       [9.9238169e-01],\n",
       "       [5.8636290e-01],\n",
       "       [6.0374779e-01],\n",
       "       [2.9249922e-03],\n",
       "       [9.9793178e-01],\n",
       "       [9.7229755e-01],\n",
       "       [4.2783135e-01],\n",
       "       [9.9219817e-01],\n",
       "       [7.3880792e-01],\n",
       "       [2.8675437e-01],\n",
       "       [7.1335628e-05],\n",
       "       [9.9406916e-01],\n",
       "       [5.3188349e-03],\n",
       "       [5.5348712e-01],\n",
       "       [2.4801074e-03],\n",
       "       [1.1945008e-04],\n",
       "       [9.9680543e-01],\n",
       "       [9.9982673e-01],\n",
       "       [3.3921477e-01],\n",
       "       [2.7807039e-01],\n",
       "       [9.1953194e-01],\n",
       "       [9.8482734e-01],\n",
       "       [1.0597424e-01],\n",
       "       [1.5617122e-01],\n",
       "       [9.6234792e-01],\n",
       "       [9.6323995e-05],\n",
       "       [4.0670910e-01],\n",
       "       [9.6583223e-01],\n",
       "       [2.0883936e-02]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:29.698714Z",
     "start_time": "2024-08-02T05:10:29.672843Z"
    }
   },
   "cell_type": "code",
   "source": "final_df['failure'] = model.predict(final_df_features)",
   "id": "a2d8c82a10e90c7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 435us/step\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:29.705751Z",
     "start_time": "2024-08-02T05:10:29.699281Z"
    }
   },
   "cell_type": "code",
   "source": "final_df",
   "id": "3c0d043ee5f1f7fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      weighted  attr_A  attr_B  attr_C  attr_E  attr_F  attr_H  attr_G  \\\n",
       "0     0.000000       4       4       5       3       5       4       6   \n",
       "1    60.000002       5       6       7       1       5       6       5   \n",
       "2    57.499999       2       5       6       4       1       2       7   \n",
       "3    64.999998       5       6       5       4       7       6       6   \n",
       "4     0.000000       6       4       3       1       4       2       7   \n",
       "..         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "473   0.000000       4       4       4       4       3       2       7   \n",
       "474  61.811566       5       4       5       9       5       5       6   \n",
       "475  56.534958       5       4       6       2       3       5       4   \n",
       "476  77.499998       5       3       5       7       4       6       3   \n",
       "477  49.845755       7       3       6       3       7       5       5   \n",
       "\n",
       "     attr_I  attr_L  ...  course_bscs  course_bsit  cfit_A  cfit_AA  cfit_BA  \\\n",
       "0         5       7  ...            1            0   False    False    False   \n",
       "1         7       5  ...            1            0   False     True    False   \n",
       "2         4       7  ...            1            0    True    False    False   \n",
       "3         7       9  ...            1            0   False     True    False   \n",
       "4         8       5  ...            1            0   False    False     True   \n",
       "..      ...     ...  ...          ...          ...     ...      ...      ...   \n",
       "473       7       9  ...            0            1   False    False    False   \n",
       "474       5       8  ...            0            1   False    False    False   \n",
       "475       5       7  ...            0            1   False    False    False   \n",
       "476       3       7  ...            0            1    True    False    False   \n",
       "477       7       4  ...            0            1   False    False    False   \n",
       "\n",
       "     cfit_H  cfit_L  cfit_M       success   failure  \n",
       "0     False    True   False  1.210673e-09  0.757611  \n",
       "1     False   False   False  5.100537e-10  0.000065  \n",
       "2     False   False   False  9.249924e-18  0.012181  \n",
       "3     False   False   False  3.563413e-20  0.204300  \n",
       "4     False   False   False  1.651953e-19  0.999433  \n",
       "..      ...     ...     ...           ...       ...  \n",
       "473   False    True   False  2.493636e-22  0.742487  \n",
       "474    True   False   False  3.318062e-19  0.006182  \n",
       "475   False    True   False  2.226829e-16  0.045137  \n",
       "476   False   False   False  5.163840e-25  0.008712  \n",
       "477   False    True   False  1.539102e-21  0.188550  \n",
       "\n",
       "[478 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted</th>\n",
       "      <th>attr_A</th>\n",
       "      <th>attr_B</th>\n",
       "      <th>attr_C</th>\n",
       "      <th>attr_E</th>\n",
       "      <th>attr_F</th>\n",
       "      <th>attr_H</th>\n",
       "      <th>attr_G</th>\n",
       "      <th>attr_I</th>\n",
       "      <th>attr_L</th>\n",
       "      <th>...</th>\n",
       "      <th>course_bscs</th>\n",
       "      <th>course_bsit</th>\n",
       "      <th>cfit_A</th>\n",
       "      <th>cfit_AA</th>\n",
       "      <th>cfit_BA</th>\n",
       "      <th>cfit_H</th>\n",
       "      <th>cfit_L</th>\n",
       "      <th>cfit_M</th>\n",
       "      <th>success</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.210673e-09</td>\n",
       "      <td>0.757611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.000002</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.100537e-10</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.499999</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9.249924e-18</td>\n",
       "      <td>0.012181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.999998</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.563413e-20</td>\n",
       "      <td>0.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.651953e-19</td>\n",
       "      <td>0.999433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.493636e-22</td>\n",
       "      <td>0.742487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>61.811566</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.318062e-19</td>\n",
       "      <td>0.006182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>56.534958</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.226829e-16</td>\n",
       "      <td>0.045137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>77.499998</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.163840e-25</td>\n",
       "      <td>0.008712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>49.845755</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.539102e-21</td>\n",
       "      <td>0.188550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:29.707927Z",
     "start_time": "2024-08-02T05:10:29.706311Z"
    }
   },
   "cell_type": "code",
   "source": "df_corr = final_df[['success', 'failure']]",
   "id": "683716e515bded0b",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:31.786572Z",
     "start_time": "2024-08-02T05:10:29.708527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# success classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "success_y = df['weighted'].apply(discretize_weights).apply(lambda x: x == 1)\n",
    "smote = SMOTE()\n",
    "x_b, y_b = smote.fit_resample(df.drop(columns=['weighted']), success_y)\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(x_b, y_b, test_size=0.2)\n",
    "from keras.src.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert data types\n",
    "X_train_b = np.asarray(X_train_f).astype(np.float64)\n",
    "y_train_b = np.asarray(y_train_f).astype(np.int16)\n",
    "X_test_b = np.asarray(X_test_f).astype(np.float64)\n",
    "y_test_b = np.asarray(y_test_f).astype(np.int16)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential([\n",
    "    InputLayer(shape=(X_train_s.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Single output unit for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_f, y_train_f, epochs=30, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test_f)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to class labels\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_f, y_pred)\n",
    "\n",
    "f'Accuracy: {accuracy}'"
   ],
   "id": "605070085422ca90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.5232 - loss: 0.6985 - val_accuracy: 0.4516 - val_loss: 0.7007\n",
      "Epoch 2/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.4904 - loss: 0.6867 - val_accuracy: 0.6290 - val_loss: 0.6748\n",
      "Epoch 3/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.5333 - loss: 0.6847 - val_accuracy: 0.6532 - val_loss: 0.6547\n",
      "Epoch 4/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6894 - loss: 0.5944 - val_accuracy: 0.7016 - val_loss: 0.5986\n",
      "Epoch 5/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7638 - loss: 0.5078 - val_accuracy: 0.6129 - val_loss: 0.6569\n",
      "Epoch 6/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7142 - loss: 0.5489 - val_accuracy: 0.6532 - val_loss: 0.6462\n",
      "Epoch 7/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8074 - loss: 0.4886 - val_accuracy: 0.7419 - val_loss: 0.5492\n",
      "Epoch 8/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7970 - loss: 0.4281 - val_accuracy: 0.7581 - val_loss: 0.5301\n",
      "Epoch 9/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8045 - loss: 0.4255 - val_accuracy: 0.6694 - val_loss: 0.7655\n",
      "Epoch 10/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8263 - loss: 0.3927 - val_accuracy: 0.7177 - val_loss: 0.5908\n",
      "Epoch 11/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8581 - loss: 0.3496 - val_accuracy: 0.7742 - val_loss: 0.4929\n",
      "Epoch 12/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8396 - loss: 0.3423 - val_accuracy: 0.6613 - val_loss: 0.6414\n",
      "Epoch 13/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8014 - loss: 0.4343 - val_accuracy: 0.7097 - val_loss: 0.8772\n",
      "Epoch 14/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8471 - loss: 0.3654 - val_accuracy: 0.7903 - val_loss: 0.4397\n",
      "Epoch 15/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8751 - loss: 0.2869 - val_accuracy: 0.7016 - val_loss: 0.7184\n",
      "Epoch 16/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8137 - loss: 0.3909 - val_accuracy: 0.8226 - val_loss: 0.4307\n",
      "Epoch 17/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8948 - loss: 0.2541 - val_accuracy: 0.8145 - val_loss: 0.3951\n",
      "Epoch 18/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9188 - loss: 0.2300 - val_accuracy: 0.8306 - val_loss: 0.4080\n",
      "Epoch 19/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8656 - loss: 0.2933 - val_accuracy: 0.8065 - val_loss: 0.4702\n",
      "Epoch 20/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9060 - loss: 0.2205 - val_accuracy: 0.7339 - val_loss: 0.5701\n",
      "Epoch 21/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8962 - loss: 0.2473 - val_accuracy: 0.7581 - val_loss: 0.6166\n",
      "Epoch 22/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9079 - loss: 0.1982 - val_accuracy: 0.8629 - val_loss: 0.3876\n",
      "Epoch 23/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9413 - loss: 0.1304 - val_accuracy: 0.8387 - val_loss: 0.4190\n",
      "Epoch 24/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9203 - loss: 0.1637 - val_accuracy: 0.8387 - val_loss: 0.4865\n",
      "Epoch 25/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8718 - loss: 0.2764 - val_accuracy: 0.8065 - val_loss: 0.4332\n",
      "Epoch 26/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9056 - loss: 0.2474 - val_accuracy: 0.8065 - val_loss: 0.5111\n",
      "Epoch 27/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9204 - loss: 0.1669 - val_accuracy: 0.8387 - val_loss: 0.5193\n",
      "Epoch 28/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9553 - loss: 0.0962 - val_accuracy: 0.8790 - val_loss: 0.5194\n",
      "Epoch 29/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9534 - loss: 0.1182 - val_accuracy: 0.8226 - val_loss: 0.7575\n",
      "Epoch 30/30\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9539 - loss: 0.1378 - val_accuracy: 0.8548 - val_loss: 0.5906\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.8903225806451613'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:31.815772Z",
     "start_time": "2024-08-02T05:10:31.787218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = model.predict(final_df_features)\n",
    "df_corr['pass'] = result"
   ],
   "id": "445213e33dde618",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 454us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m3/0c2cdk9j3lvc81rygncqrfy40000gn/T/ipykernel_4311/1717956343.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_corr['pass'] = result\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:31.819521Z",
     "start_time": "2024-08-02T05:10:31.816397Z"
    }
   },
   "cell_type": "code",
   "source": "df_corr.corr()",
   "id": "1f7c67d23010afc7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          success   failure      pass\n",
       "success  1.000000 -0.117463 -0.110536\n",
       "failure -0.117463  1.000000  0.799235\n",
       "pass    -0.110536  0.799235  1.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>failure</th>\n",
       "      <th>pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>success</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.117463</td>\n",
       "      <td>-0.110536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failure</th>\n",
       "      <td>-0.117463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pass</th>\n",
       "      <td>-0.110536</td>\n",
       "      <td>0.799235</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:31.823737Z",
     "start_time": "2024-08-02T05:10:31.820332Z"
    }
   },
   "cell_type": "code",
   "source": "df_corr",
   "id": "960d56255ce682bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          success   failure          pass\n",
       "0    1.210673e-09  0.757611  9.992988e-01\n",
       "1    5.100537e-10  0.000065  2.185780e-08\n",
       "2    9.249924e-18  0.012181  3.329029e-02\n",
       "3    3.563413e-20  0.204300  1.163027e-02\n",
       "4    1.651953e-19  0.999433  9.994544e-01\n",
       "..            ...       ...           ...\n",
       "473  2.493636e-22  0.742487  9.963731e-01\n",
       "474  3.318062e-19  0.006182  6.388703e-03\n",
       "475  2.226829e-16  0.045137  3.432620e-03\n",
       "476  5.163840e-25  0.008712  1.506115e-02\n",
       "477  1.539102e-21  0.188550  7.471893e-02\n",
       "\n",
       "[478 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>failure</th>\n",
       "      <th>pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.210673e-09</td>\n",
       "      <td>0.757611</td>\n",
       "      <td>9.992988e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.100537e-10</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>2.185780e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.249924e-18</td>\n",
       "      <td>0.012181</td>\n",
       "      <td>3.329029e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.563413e-20</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>1.163027e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.651953e-19</td>\n",
       "      <td>0.999433</td>\n",
       "      <td>9.994544e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2.493636e-22</td>\n",
       "      <td>0.742487</td>\n",
       "      <td>9.963731e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>3.318062e-19</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>6.388703e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2.226829e-16</td>\n",
       "      <td>0.045137</td>\n",
       "      <td>3.432620e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>5.163840e-25</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>1.506115e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1.539102e-21</td>\n",
       "      <td>0.188550</td>\n",
       "      <td>7.471893e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:31.826325Z",
     "start_time": "2024-08-02T05:10:31.824178Z"
    }
   },
   "cell_type": "code",
   "source": "merged_input_features = pd.concat([df_corr, pd.DataFrame(final_df_features)], axis=1)",
   "id": "80264b8a5e6cc4be",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:31.835270Z",
     "start_time": "2024-08-02T05:10:31.826776Z"
    }
   },
   "cell_type": "code",
   "source": "merged_input_features",
   "id": "e1b09254a4df15c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          success   failure          pass    0    1    2    3    4    5    6  \\\n",
       "0    1.210673e-09  0.757611  9.992988e-01  4.0  4.0  5.0  3.0  5.0  4.0  6.0   \n",
       "1    5.100537e-10  0.000065  2.185780e-08  5.0  6.0  7.0  1.0  5.0  6.0  5.0   \n",
       "2    9.249924e-18  0.012181  3.329029e-02  2.0  5.0  6.0  4.0  1.0  2.0  7.0   \n",
       "3    3.563413e-20  0.204300  1.163027e-02  5.0  6.0  5.0  4.0  7.0  6.0  6.0   \n",
       "4    1.651953e-19  0.999433  9.994544e-01  6.0  4.0  3.0  1.0  4.0  2.0  7.0   \n",
       "..            ...       ...           ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "473  2.493636e-22  0.742487  9.963731e-01  4.0  4.0  4.0  4.0  3.0  2.0  7.0   \n",
       "474  3.318062e-19  0.006182  6.388703e-03  5.0  4.0  5.0  9.0  5.0  5.0  6.0   \n",
       "475  2.226829e-16  0.045137  3.432620e-03  5.0  4.0  6.0  2.0  3.0  5.0  4.0   \n",
       "476  5.163840e-25  0.008712  1.506115e-02  5.0  3.0  5.0  7.0  4.0  6.0  3.0   \n",
       "477  1.539102e-21  0.188550  7.471893e-02  7.0  3.0  6.0  3.0  7.0  5.0  5.0   \n",
       "\n",
       "     ...   19   20   21   22   23   24   25   26   27   28  \n",
       "0    ...  4.0  5.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1    ...  3.0  6.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "2    ...  4.0  7.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3    ...  4.0  6.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "4    ...  1.0  6.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "473  ...  4.0  7.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "474  ...  8.0  7.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "475  ...  3.0  5.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "476  ...  7.0  5.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "477  ...  4.0  5.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[478 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>failure</th>\n",
       "      <th>pass</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.210673e-09</td>\n",
       "      <td>0.757611</td>\n",
       "      <td>9.992988e-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.100537e-10</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>2.185780e-08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.249924e-18</td>\n",
       "      <td>0.012181</td>\n",
       "      <td>3.329029e-02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.563413e-20</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>1.163027e-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.651953e-19</td>\n",
       "      <td>0.999433</td>\n",
       "      <td>9.994544e-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2.493636e-22</td>\n",
       "      <td>0.742487</td>\n",
       "      <td>9.963731e-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>3.318062e-19</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>6.388703e-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2.226829e-16</td>\n",
       "      <td>0.045137</td>\n",
       "      <td>3.432620e-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>5.163840e-25</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>1.506115e-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1.539102e-21</td>\n",
       "      <td>0.188550</td>\n",
       "      <td>7.471893e-02</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:33.833876Z",
     "start_time": "2024-08-02T05:10:31.835934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y_one_hot = pd.get_dummies(final_y)\n",
    "final_model = Sequential([\n",
    "    InputLayer(shape=(merged_input_features.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(3, activation='sigmoid')],\n",
    ")\n",
    "final_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "final_model.fit(merged_input_features, y_one_hot, epochs=30, batch_size=32, validation_split=0.2, verbose=1)\n",
    "y_pred_prob = model.predict(X_test_f)"
   ],
   "id": "b6ec82ce00890e55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.4928 - loss: 1.0082 - val_accuracy: 0.8542 - val_loss: 0.5289\n",
      "Epoch 2/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7551 - loss: 0.7027 - val_accuracy: 0.8542 - val_loss: 0.4721\n",
      "Epoch 3/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7558 - loss: 0.6531 - val_accuracy: 0.8542 - val_loss: 0.4505\n",
      "Epoch 4/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7474 - loss: 0.5985 - val_accuracy: 0.8542 - val_loss: 0.4263\n",
      "Epoch 5/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7810 - loss: 0.5167 - val_accuracy: 0.8854 - val_loss: 0.4340\n",
      "Epoch 6/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8280 - loss: 0.4540 - val_accuracy: 0.8542 - val_loss: 0.5264\n",
      "Epoch 7/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8380 - loss: 0.4563 - val_accuracy: 0.8854 - val_loss: 0.3441\n",
      "Epoch 8/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8251 - loss: 0.4065 - val_accuracy: 0.8021 - val_loss: 0.4423\n",
      "Epoch 9/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8591 - loss: 0.3462 - val_accuracy: 0.8854 - val_loss: 0.3303\n",
      "Epoch 10/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8814 - loss: 0.3094 - val_accuracy: 0.9167 - val_loss: 0.3093\n",
      "Epoch 11/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8736 - loss: 0.3152 - val_accuracy: 0.8958 - val_loss: 0.3839\n",
      "Epoch 12/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8640 - loss: 0.3338 - val_accuracy: 0.8125 - val_loss: 0.3811\n",
      "Epoch 13/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8332 - loss: 0.3298 - val_accuracy: 0.7917 - val_loss: 0.3970\n",
      "Epoch 14/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8311 - loss: 0.3736 - val_accuracy: 0.8854 - val_loss: 0.3155\n",
      "Epoch 15/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8611 - loss: 0.3085 - val_accuracy: 0.9062 - val_loss: 0.3035\n",
      "Epoch 16/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9144 - loss: 0.2149 - val_accuracy: 0.8958 - val_loss: 0.2838\n",
      "Epoch 17/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9304 - loss: 0.1998 - val_accuracy: 0.9062 - val_loss: 0.2667\n",
      "Epoch 18/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9382 - loss: 0.1755 - val_accuracy: 0.8958 - val_loss: 0.2838\n",
      "Epoch 19/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9434 - loss: 0.1917 - val_accuracy: 0.9062 - val_loss: 0.2793\n",
      "Epoch 20/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9407 - loss: 0.1709 - val_accuracy: 0.9062 - val_loss: 0.3125\n",
      "Epoch 21/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9090 - loss: 0.2518 - val_accuracy: 0.9062 - val_loss: 0.3850\n",
      "Epoch 22/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9366 - loss: 0.1601 - val_accuracy: 0.8958 - val_loss: 0.3102\n",
      "Epoch 23/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9223 - loss: 0.1870 - val_accuracy: 0.8958 - val_loss: 0.4290\n",
      "Epoch 24/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9398 - loss: 0.1510 - val_accuracy: 0.9062 - val_loss: 0.3610\n",
      "Epoch 25/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9336 - loss: 0.1671 - val_accuracy: 0.8854 - val_loss: 0.3165\n",
      "Epoch 26/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9438 - loss: 0.1483 - val_accuracy: 0.8854 - val_loss: 0.3150\n",
      "Epoch 27/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9662 - loss: 0.0923 - val_accuracy: 0.8958 - val_loss: 0.4882\n",
      "Epoch 28/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9414 - loss: 0.1791 - val_accuracy: 0.8958 - val_loss: 0.3249\n",
      "Epoch 29/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9801 - loss: 0.0777 - val_accuracy: 0.9062 - val_loss: 0.3406\n",
      "Epoch 30/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9693 - loss: 0.0941 - val_accuracy: 0.8854 - val_loss: 0.4118\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 623us/step\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:33.907587Z",
     "start_time": "2024-08-02T05:10:33.834509Z"
    }
   },
   "cell_type": "code",
   "source": "final_model.predict(merged_input_features)",
   "id": "795f618ad0993063",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.96430635, 0.62509644, 0.01957279],\n",
       "       [0.23072335, 0.9993999 , 0.01820329],\n",
       "       [0.2668395 , 0.99964947, 0.01078043],\n",
       "       ...,\n",
       "       [0.26993436, 0.99980867, 0.00683836],\n",
       "       [0.42017525, 0.99950963, 0.00650586],\n",
       "       [0.3345277 , 0.9981437 , 0.02482418]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:33.911745Z",
     "start_time": "2024-08-02T05:10:33.908395Z"
    }
   },
   "cell_type": "code",
   "source": "y_one_hot",
   "id": "396ecdabef685963",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         0      1      2\n",
       "0     True  False  False\n",
       "1    False   True  False\n",
       "2    False   True  False\n",
       "3    False   True  False\n",
       "4     True  False  False\n",
       "..     ...    ...    ...\n",
       "473   True  False  False\n",
       "474  False   True  False\n",
       "475  False   True  False\n",
       "476  False   True  False\n",
       "477   True  False  False\n",
       "\n",
       "[478 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:10:33.916597Z",
     "start_time": "2024-08-02T05:10:33.915006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K"
   ],
   "id": "ad90af699723e2a4",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:17:20.008468Z",
     "start_time": "2024-08-02T05:17:10.923026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# Assuming final_y and merged_input_features are already defined\n",
    "\n",
    "# One-hot encode the target variable\n",
    "y_one_hot = pd.get_dummies(final_y)\n",
    "\n",
    "# Define the model creation function\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        InputLayer(shape=(input_shape,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Set up k-fold cross-validation\n",
    "n_splits = 5\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "fold_no = 1\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "for train, test in kfold.split(merged_input_features, y_one_hot):\n",
    "    model = create_model(merged_input_features.shape[1])\n",
    "    \n",
    "    history = model.fit(\n",
    "        merged_input_features.iloc[train], \n",
    "        y_one_hot.iloc[train], \n",
    "        epochs=30, \n",
    "        batch_size=32, \n",
    "        validation_data=(merged_input_features.iloc[test], y_one_hot.iloc[test]),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    scores = model.evaluate(merged_input_features.iloc[test], y_one_hot.iloc[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    \n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    fold_no += 1\n",
    "\n",
    "\n",
    "\n",
    "# Train the final model on all data\n",
    "final_model = create_model(merged_input_features.shape[1])\n",
    "final_model.fit(merged_input_features, y_one_hot, epochs=30, batch_size=32, verbose=1)\n",
    "# Print average scores\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n"
   ],
   "id": "56097447849c998b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6416 - loss: 0.7694 - val_accuracy: 0.7812 - val_loss: 0.6404\n",
      "Epoch 2/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7849 - loss: 0.6308 - val_accuracy: 0.7812 - val_loss: 0.5808\n",
      "Epoch 3/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7772 - loss: 0.6095 - val_accuracy: 0.7812 - val_loss: 0.5703\n",
      "Epoch 4/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7802 - loss: 0.6020 - val_accuracy: 0.7812 - val_loss: 0.5540\n",
      "Epoch 5/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7785 - loss: 0.5749 - val_accuracy: 0.7812 - val_loss: 0.5621\n",
      "Epoch 6/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8071 - loss: 0.4612 - val_accuracy: 0.8125 - val_loss: 0.4751\n",
      "Epoch 7/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8391 - loss: 0.4519 - val_accuracy: 0.8542 - val_loss: 0.4562\n",
      "Epoch 8/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8433 - loss: 0.5018 - val_accuracy: 0.7812 - val_loss: 0.5116\n",
      "Epoch 9/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7874 - loss: 0.5040 - val_accuracy: 0.8229 - val_loss: 0.4479\n",
      "Epoch 10/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8581 - loss: 0.3611 - val_accuracy: 0.8021 - val_loss: 0.5016\n",
      "Epoch 11/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8621 - loss: 0.3433 - val_accuracy: 0.8542 - val_loss: 0.4433\n",
      "Epoch 12/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8735 - loss: 0.3150 - val_accuracy: 0.8438 - val_loss: 0.4245\n",
      "Epoch 13/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8762 - loss: 0.3071 - val_accuracy: 0.8438 - val_loss: 0.4257\n",
      "Epoch 14/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8982 - loss: 0.2392 - val_accuracy: 0.8333 - val_loss: 0.5090\n",
      "Epoch 15/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9057 - loss: 0.1987 - val_accuracy: 0.8854 - val_loss: 0.4220\n",
      "Epoch 16/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8886 - loss: 0.2851 - val_accuracy: 0.8542 - val_loss: 0.4697\n",
      "Epoch 17/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8936 - loss: 0.2401 - val_accuracy: 0.8646 - val_loss: 0.4652\n",
      "Epoch 18/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9605 - loss: 0.1361 - val_accuracy: 0.8438 - val_loss: 0.5842\n",
      "Epoch 19/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9601 - loss: 0.1345 - val_accuracy: 0.8438 - val_loss: 0.5371\n",
      "Epoch 20/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9435 - loss: 0.1236 - val_accuracy: 0.8646 - val_loss: 0.4788\n",
      "Epoch 21/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9295 - loss: 0.1731 - val_accuracy: 0.8229 - val_loss: 0.5908\n",
      "Epoch 22/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9576 - loss: 0.1017 - val_accuracy: 0.8438 - val_loss: 0.6542\n",
      "Epoch 23/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9651 - loss: 0.1295 - val_accuracy: 0.8646 - val_loss: 0.4914\n",
      "Epoch 24/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9541 - loss: 0.1274 - val_accuracy: 0.8438 - val_loss: 0.7230\n",
      "Epoch 25/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9453 - loss: 0.1475 - val_accuracy: 0.7708 - val_loss: 0.8702\n",
      "Epoch 26/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8750 - loss: 0.3474 - val_accuracy: 0.8750 - val_loss: 0.4647\n",
      "Epoch 27/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9602 - loss: 0.1091 - val_accuracy: 0.8438 - val_loss: 0.7227\n",
      "Epoch 28/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9667 - loss: 0.0607 - val_accuracy: 0.8438 - val_loss: 0.7740\n",
      "Epoch 29/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9725 - loss: 0.0600 - val_accuracy: 0.8542 - val_loss: 0.6541\n",
      "Epoch 30/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9728 - loss: 0.0547 - val_accuracy: 0.8542 - val_loss: 0.8258\n",
      "Score for fold 1: loss of 0.82584148645401; compile_metrics of 85.41666865348816%\n",
      "Epoch 1/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.5248 - loss: 0.9052 - val_accuracy: 0.7500 - val_loss: 0.6541\n",
      "Epoch 2/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8052 - loss: 0.5756 - val_accuracy: 0.7500 - val_loss: 0.6555\n",
      "Epoch 3/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7880 - loss: 0.5852 - val_accuracy: 0.7500 - val_loss: 0.6867\n",
      "Epoch 4/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8086 - loss: 0.5381 - val_accuracy: 0.7500 - val_loss: 0.6473\n",
      "Epoch 5/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7913 - loss: 0.5775 - val_accuracy: 0.7500 - val_loss: 0.6394\n",
      "Epoch 6/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8035 - loss: 0.5435 - val_accuracy: 0.7500 - val_loss: 0.6288\n",
      "Epoch 7/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7974 - loss: 0.5191 - val_accuracy: 0.7500 - val_loss: 0.6018\n",
      "Epoch 8/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8035 - loss: 0.4628 - val_accuracy: 0.7500 - val_loss: 0.6505\n",
      "Epoch 9/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7758 - loss: 0.5137 - val_accuracy: 0.8021 - val_loss: 0.4857\n",
      "Epoch 10/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8544 - loss: 0.3709 - val_accuracy: 0.8229 - val_loss: 0.5197\n",
      "Epoch 11/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8627 - loss: 0.3949 - val_accuracy: 0.8229 - val_loss: 0.5195\n",
      "Epoch 12/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8560 - loss: 0.4083 - val_accuracy: 0.8646 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8712 - loss: 0.3550 - val_accuracy: 0.8750 - val_loss: 0.3512\n",
      "Epoch 14/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9091 - loss: 0.2520 - val_accuracy: 0.8958 - val_loss: 0.3205\n",
      "Epoch 15/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8957 - loss: 0.2597 - val_accuracy: 0.8646 - val_loss: 0.4345\n",
      "Epoch 16/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9225 - loss: 0.1981 - val_accuracy: 0.8542 - val_loss: 0.3938\n",
      "Epoch 17/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9237 - loss: 0.2139 - val_accuracy: 0.8750 - val_loss: 0.3525\n",
      "Epoch 18/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8944 - loss: 0.2861 - val_accuracy: 0.8854 - val_loss: 0.3845\n",
      "Epoch 19/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9044 - loss: 0.2845 - val_accuracy: 0.8438 - val_loss: 0.5233\n",
      "Epoch 20/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9236 - loss: 0.1862 - val_accuracy: 0.8646 - val_loss: 0.4884\n",
      "Epoch 21/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9557 - loss: 0.1559 - val_accuracy: 0.8958 - val_loss: 0.3759\n",
      "Epoch 22/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9478 - loss: 0.1384 - val_accuracy: 0.8646 - val_loss: 0.4069\n",
      "Epoch 23/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9448 - loss: 0.1537 - val_accuracy: 0.8750 - val_loss: 0.5856\n",
      "Epoch 24/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9460 - loss: 0.1290 - val_accuracy: 0.8542 - val_loss: 0.6633\n",
      "Epoch 25/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9650 - loss: 0.1250 - val_accuracy: 0.8854 - val_loss: 0.4202\n",
      "Epoch 26/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9604 - loss: 0.1152 - val_accuracy: 0.8854 - val_loss: 0.6127\n",
      "Epoch 27/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9765 - loss: 0.0774 - val_accuracy: 0.8021 - val_loss: 0.7346\n",
      "Epoch 28/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9290 - loss: 0.2067 - val_accuracy: 0.8438 - val_loss: 0.5457\n",
      "Epoch 29/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9282 - loss: 0.1698 - val_accuracy: 0.9062 - val_loss: 0.5389\n",
      "Epoch 30/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9649 - loss: 0.1069 - val_accuracy: 0.8646 - val_loss: 0.5965\n",
      "Score for fold 2: loss of 0.5964912176132202; compile_metrics of 86.45833134651184%\n",
      "Epoch 1/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6228 - loss: 0.7889 - val_accuracy: 0.7812 - val_loss: 0.6067\n",
      "Epoch 2/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7672 - loss: 0.6136 - val_accuracy: 0.7812 - val_loss: 0.6456\n",
      "Epoch 3/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7687 - loss: 0.6413 - val_accuracy: 0.7812 - val_loss: 0.6196\n",
      "Epoch 4/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7657 - loss: 0.6405 - val_accuracy: 0.7812 - val_loss: 0.5789\n",
      "Epoch 5/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8141 - loss: 0.4460 - val_accuracy: 0.7917 - val_loss: 0.5005\n",
      "Epoch 6/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8050 - loss: 0.4375 - val_accuracy: 0.8438 - val_loss: 0.4303\n",
      "Epoch 7/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8764 - loss: 0.3750 - val_accuracy: 0.8542 - val_loss: 0.4451\n",
      "Epoch 8/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8678 - loss: 0.3624 - val_accuracy: 0.8021 - val_loss: 0.4607\n",
      "Epoch 9/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8269 - loss: 0.3518 - val_accuracy: 0.8542 - val_loss: 0.4474\n",
      "Epoch 10/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8575 - loss: 0.3572 - val_accuracy: 0.8438 - val_loss: 0.5234\n",
      "Epoch 11/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9080 - loss: 0.2836 - val_accuracy: 0.8229 - val_loss: 0.6078\n",
      "Epoch 12/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8995 - loss: 0.2806 - val_accuracy: 0.8438 - val_loss: 0.4505\n",
      "Epoch 13/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9261 - loss: 0.2788 - val_accuracy: 0.8333 - val_loss: 0.4866\n",
      "Epoch 14/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9000 - loss: 0.2858 - val_accuracy: 0.8542 - val_loss: 0.5233\n",
      "Epoch 15/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9018 - loss: 0.2832 - val_accuracy: 0.7917 - val_loss: 0.5938\n",
      "Epoch 16/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8900 - loss: 0.2601 - val_accuracy: 0.8646 - val_loss: 0.4362\n",
      "Epoch 17/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9156 - loss: 0.2018 - val_accuracy: 0.8542 - val_loss: 0.4793\n",
      "Epoch 18/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9131 - loss: 0.2119 - val_accuracy: 0.8646 - val_loss: 0.4940\n",
      "Epoch 19/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9065 - loss: 0.2473 - val_accuracy: 0.8750 - val_loss: 0.4847\n",
      "Epoch 20/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9173 - loss: 0.2437 - val_accuracy: 0.8750 - val_loss: 0.4796\n",
      "Epoch 21/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9140 - loss: 0.2061 - val_accuracy: 0.8542 - val_loss: 0.4495\n",
      "Epoch 22/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9336 - loss: 0.1537 - val_accuracy: 0.8646 - val_loss: 0.4862\n",
      "Epoch 23/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9248 - loss: 0.1715 - val_accuracy: 0.8750 - val_loss: 0.4715\n",
      "Epoch 24/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9452 - loss: 0.1424 - val_accuracy: 0.8438 - val_loss: 0.5172\n",
      "Epoch 25/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9520 - loss: 0.1240 - val_accuracy: 0.8646 - val_loss: 0.6390\n",
      "Epoch 26/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9630 - loss: 0.1264 - val_accuracy: 0.8750 - val_loss: 0.6109\n",
      "Epoch 27/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9565 - loss: 0.1158 - val_accuracy: 0.8646 - val_loss: 0.6611\n",
      "Epoch 28/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9745 - loss: 0.0895 - val_accuracy: 0.8542 - val_loss: 0.7961\n",
      "Epoch 29/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9406 - loss: 0.1325 - val_accuracy: 0.8125 - val_loss: 0.7403\n",
      "Epoch 30/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9698 - loss: 0.0834 - val_accuracy: 0.8438 - val_loss: 0.8145\n",
      "Score for fold 3: loss of 0.8144620060920715; compile_metrics of 84.375%\n",
      "Epoch 1/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.7843 - loss: 0.7715 - val_accuracy: 0.8632 - val_loss: 0.4524\n",
      "Epoch 2/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7656 - loss: 0.6236 - val_accuracy: 0.8632 - val_loss: 0.4329\n",
      "Epoch 3/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7863 - loss: 0.5498 - val_accuracy: 0.8632 - val_loss: 0.5378\n",
      "Epoch 4/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7803 - loss: 0.5730 - val_accuracy: 0.8632 - val_loss: 0.4295\n",
      "Epoch 5/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7800 - loss: 0.5118 - val_accuracy: 0.8632 - val_loss: 0.3741\n",
      "Epoch 6/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8000 - loss: 0.4455 - val_accuracy: 0.8105 - val_loss: 0.4022\n",
      "Epoch 7/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8247 - loss: 0.3698 - val_accuracy: 0.7053 - val_loss: 0.6111\n",
      "Epoch 8/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8538 - loss: 0.3985 - val_accuracy: 0.8526 - val_loss: 0.3594\n",
      "Epoch 9/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8878 - loss: 0.2733 - val_accuracy: 0.8000 - val_loss: 0.4763\n",
      "Epoch 10/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9293 - loss: 0.2224 - val_accuracy: 0.8632 - val_loss: 0.3809\n",
      "Epoch 11/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9248 - loss: 0.2253 - val_accuracy: 0.8211 - val_loss: 0.4430\n",
      "Epoch 12/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9253 - loss: 0.1900 - val_accuracy: 0.9053 - val_loss: 0.3313\n",
      "Epoch 13/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9196 - loss: 0.1995 - val_accuracy: 0.7368 - val_loss: 0.5845\n",
      "Epoch 14/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9011 - loss: 0.2308 - val_accuracy: 0.8737 - val_loss: 0.3414\n",
      "Epoch 15/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9345 - loss: 0.1846 - val_accuracy: 0.8842 - val_loss: 0.3782\n",
      "Epoch 16/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9223 - loss: 0.2284 - val_accuracy: 0.9053 - val_loss: 0.3451\n",
      "Epoch 17/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9375 - loss: 0.1549 - val_accuracy: 0.8526 - val_loss: 0.3632\n",
      "Epoch 18/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9031 - loss: 0.2365 - val_accuracy: 0.8737 - val_loss: 0.3667\n",
      "Epoch 19/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9351 - loss: 0.1635 - val_accuracy: 0.9263 - val_loss: 0.3071\n",
      "Epoch 20/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9388 - loss: 0.1745 - val_accuracy: 0.9474 - val_loss: 0.2482\n",
      "Epoch 21/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9388 - loss: 0.1679 - val_accuracy: 0.9053 - val_loss: 0.2851\n",
      "Epoch 22/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9690 - loss: 0.0940 - val_accuracy: 0.9263 - val_loss: 0.3384\n",
      "Epoch 23/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9597 - loss: 0.1049 - val_accuracy: 0.8842 - val_loss: 0.3721\n",
      "Epoch 24/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9740 - loss: 0.0724 - val_accuracy: 0.8842 - val_loss: 0.4724\n",
      "Epoch 25/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9663 - loss: 0.1013 - val_accuracy: 0.8632 - val_loss: 0.5091\n",
      "Epoch 26/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9591 - loss: 0.1070 - val_accuracy: 0.9263 - val_loss: 0.4647\n",
      "Epoch 27/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9335 - loss: 0.1764 - val_accuracy: 0.9263 - val_loss: 0.3535\n",
      "Epoch 28/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9692 - loss: 0.0612 - val_accuracy: 0.8737 - val_loss: 0.6171\n",
      "Epoch 29/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9745 - loss: 0.0670 - val_accuracy: 0.8842 - val_loss: 0.4981\n",
      "Epoch 30/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9864 - loss: 0.0436 - val_accuracy: 0.9053 - val_loss: 0.5073\n",
      "Score for fold 4: loss of 0.5072886347770691; compile_metrics of 90.52631855010986%\n",
      "Epoch 1/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5962 - loss: 0.7855 - val_accuracy: 0.7579 - val_loss: 0.6998\n",
      "Epoch 2/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7852 - loss: 0.6188 - val_accuracy: 0.7579 - val_loss: 0.6398\n",
      "Epoch 3/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8082 - loss: 0.5426 - val_accuracy: 0.7579 - val_loss: 0.6357\n",
      "Epoch 4/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7872 - loss: 0.5626 - val_accuracy: 0.7579 - val_loss: 0.6207\n",
      "Epoch 5/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7974 - loss: 0.5220 - val_accuracy: 0.7684 - val_loss: 0.5768\n",
      "Epoch 6/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8401 - loss: 0.4104 - val_accuracy: 0.8211 - val_loss: 0.5032\n",
      "Epoch 7/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9000 - loss: 0.3239 - val_accuracy: 0.8526 - val_loss: 0.4607\n",
      "Epoch 8/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8812 - loss: 0.3330 - val_accuracy: 0.8737 - val_loss: 0.4389\n",
      "Epoch 9/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9093 - loss: 0.2782 - val_accuracy: 0.8842 - val_loss: 0.4031\n",
      "Epoch 10/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8914 - loss: 0.2955 - val_accuracy: 0.8105 - val_loss: 0.6529\n",
      "Epoch 11/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8788 - loss: 0.3447 - val_accuracy: 0.8947 - val_loss: 0.3821\n",
      "Epoch 12/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8993 - loss: 0.2912 - val_accuracy: 0.8632 - val_loss: 0.4048\n",
      "Epoch 13/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9176 - loss: 0.2449 - val_accuracy: 0.8632 - val_loss: 0.4307\n",
      "Epoch 14/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9275 - loss: 0.1891 - val_accuracy: 0.8316 - val_loss: 0.5694\n",
      "Epoch 15/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8661 - loss: 0.2990 - val_accuracy: 0.8947 - val_loss: 0.3780\n",
      "Epoch 16/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9027 - loss: 0.2060 - val_accuracy: 0.8842 - val_loss: 0.4710\n",
      "Epoch 17/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9179 - loss: 0.2029 - val_accuracy: 0.8737 - val_loss: 0.3857\n",
      "Epoch 18/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9440 - loss: 0.1397 - val_accuracy: 0.8947 - val_loss: 0.4617\n",
      "Epoch 19/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9633 - loss: 0.1304 - val_accuracy: 0.8632 - val_loss: 0.4296\n",
      "Epoch 20/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9532 - loss: 0.1378 - val_accuracy: 0.9053 - val_loss: 0.3459\n",
      "Epoch 21/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9644 - loss: 0.1137 - val_accuracy: 0.8947 - val_loss: 0.3666\n",
      "Epoch 22/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9474 - loss: 0.1391 - val_accuracy: 0.8947 - val_loss: 0.4586\n",
      "Epoch 23/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9523 - loss: 0.1182 - val_accuracy: 0.8842 - val_loss: 0.3856\n",
      "Epoch 24/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9623 - loss: 0.1087 - val_accuracy: 0.8211 - val_loss: 0.6956\n",
      "Epoch 25/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9353 - loss: 0.1888 - val_accuracy: 0.8842 - val_loss: 0.3845\n",
      "Epoch 26/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9269 - loss: 0.1860 - val_accuracy: 0.8316 - val_loss: 0.5962\n",
      "Epoch 27/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9389 - loss: 0.1554 - val_accuracy: 0.8842 - val_loss: 0.3650\n",
      "Epoch 28/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9521 - loss: 0.1235 - val_accuracy: 0.8842 - val_loss: 0.3727\n",
      "Epoch 29/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9699 - loss: 0.0864 - val_accuracy: 0.9053 - val_loss: 0.4527\n",
      "Epoch 30/30\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.9602 - loss: 0.0931 - val_accuracy: 0.8105 - val_loss: 0.7141\n",
      "Score for fold 5: loss of 0.7140589952468872; compile_metrics of 81.05263113975525%\n",
      "Epoch 1/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 792us/step - accuracy: 0.6574 - loss: 0.8132\n",
      "Epoch 2/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 775us/step - accuracy: 0.7991 - loss: 0.6003\n",
      "Epoch 3/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 753us/step - accuracy: 0.7868 - loss: 0.5651\n",
      "Epoch 4/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 791us/step - accuracy: 0.7769 - loss: 0.5890\n",
      "Epoch 5/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 761us/step - accuracy: 0.7805 - loss: 0.5199\n",
      "Epoch 6/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8112 - loss: 0.4195\n",
      "Epoch 7/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 924us/step - accuracy: 0.7409 - loss: 0.5218\n",
      "Epoch 8/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 933us/step - accuracy: 0.8460 - loss: 0.4238\n",
      "Epoch 9/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 931us/step - accuracy: 0.8647 - loss: 0.3702\n",
      "Epoch 10/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 901us/step - accuracy: 0.8640 - loss: 0.3860\n",
      "Epoch 11/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8569 - loss: 0.4058\n",
      "Epoch 12/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 920us/step - accuracy: 0.8994 - loss: 0.2884\n",
      "Epoch 13/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 923us/step - accuracy: 0.9041 - loss: 0.3032\n",
      "Epoch 14/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 870us/step - accuracy: 0.8901 - loss: 0.2834\n",
      "Epoch 15/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 969us/step - accuracy: 0.9221 - loss: 0.2132\n",
      "Epoch 16/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 915us/step - accuracy: 0.8499 - loss: 0.3720\n",
      "Epoch 17/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 951us/step - accuracy: 0.9083 - loss: 0.2561\n",
      "Epoch 18/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9459 - loss: 0.1789\n",
      "Epoch 19/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9119 - loss: 0.2852\n",
      "Epoch 20/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9041 - loss: 0.2087\n",
      "Epoch 21/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9305 - loss: 0.1874\n",
      "Epoch 22/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 919us/step - accuracy: 0.9294 - loss: 0.2182\n",
      "Epoch 23/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 876us/step - accuracy: 0.9436 - loss: 0.1460\n",
      "Epoch 24/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 978us/step - accuracy: 0.9546 - loss: 0.1466\n",
      "Epoch 25/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 896us/step - accuracy: 0.9570 - loss: 0.1121\n",
      "Epoch 26/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 889us/step - accuracy: 0.9519 - loss: 0.1436\n",
      "Epoch 27/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 946us/step - accuracy: 0.9725 - loss: 0.0952\n",
      "Epoch 28/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 910us/step - accuracy: 0.9468 - loss: 0.1273\n",
      "Epoch 29/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 870us/step - accuracy: 0.9646 - loss: 0.1013\n",
      "Epoch 30/30\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 945us/step - accuracy: 0.9635 - loss: 0.1144\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "> Fold 1 - Loss: 0.82584148645401 - Accuracy: 85.41666865348816%\n",
      "> Fold 2 - Loss: 0.5964912176132202 - Accuracy: 86.45833134651184%\n",
      "> Fold 3 - Loss: 0.8144620060920715 - Accuracy: 84.375%\n",
      "> Fold 4 - Loss: 0.5072886347770691 - Accuracy: 90.52631855010986%\n",
      "> Fold 5 - Loss: 0.7140589952468872 - Accuracy: 81.05263113975525%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 85.56578993797302 (+- 3.072858423343953)\n",
      "> Loss: 0.6916284680366516\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:17:20.016117Z",
     "start_time": "2024-08-02T05:17:20.009458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import mysql.connector\n",
    "\n",
    "def run_analysis(tag_ids):\n",
    "    def get_engine():\n",
    "        return mysql.connector.connect(\n",
    "            host='monorail.proxy.rlwy.net',\n",
    "            port=45826,\n",
    "            user='root',\n",
    "            password='VoUeejgBIkMgYiPmYHxMFsIXffwxCKBK',\n",
    "            database='railway'\n",
    "        )\n",
    "\n",
    "    def fetch_data_as_dataframe(connection, query: str) -> pd.DataFrame:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        result_set = cursor.fetchall()\n",
    "        column_names = cursor.column_names\n",
    "        cursor.close()\n",
    "        df = pd.DataFrame(result_set, columns=column_names)\n",
    "        return df.dropna()\n",
    "\n",
    "    def discretize_weights(weight):\n",
    "        if weight < 50:\n",
    "            return 0\n",
    "        if 50 <= weight < 95:\n",
    "            return 1\n",
    "        if 95 <= weight <= 100:\n",
    "            return 2\n",
    "\n",
    "    # Modify the SQL query to use the provided tag_ids\n",
    "    tag_ids_str = ', '.join(map(str, tag_ids))\n",
    "    query = f\"\"\"\n",
    "    SELECT ((grade-1)/4)*100 as weighted, attr_A, attr_B, attr_C, attr_E, attr_F, attr_H, attr_G, attr_I, attr_L, attr_M, attr_N, attr_O, attr_Q1, attr_Q2,\n",
    "            attr_Q3, attr_Q4, attr_EX, attr_AX, attr_TM, attr_IN, attr_SC,\n",
    "            cfit,\n",
    "            CASE when course = 'BSCS' then 1 else 0 end as course_bscs,\n",
    "            CASE when course = 'BSIT' then 1 else 0 end as course_bsit\n",
    "    FROM students\n",
    "    INNER JOIN assessments s on s.student_id = students.Id WHERE tagID in ({tag_ids_str});\n",
    "    \"\"\"\n",
    "\n",
    "    df = fetch_data_as_dataframe(get_engine(), query)\n",
    "    df = pd.get_dummies(df, columns=['cfit'])\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    final_y = df['weighted'].apply(discretize_weights)\n",
    "    final_df = df.copy()\n",
    "    final_df_features = np.asarray(final_df.drop(columns=['weighted']), np.float64)\n",
    "\n",
    "    def train_binary_classifier(X, y):\n",
    "        smote = SMOTE()\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2)\n",
    "\n",
    "        model = Sequential([\n",
    "            InputLayer(shape=(X_train.shape[1],)),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, verbose=0)\n",
    "        print('Train model initial')\n",
    "        return model.predict(final_df_features)\n",
    "\n",
    "    df_corr = pd.DataFrame()\n",
    "    df_corr['success'] = train_binary_classifier(df.drop(columns=['weighted']), final_y.apply(lambda x: x == 2))\n",
    "    df_corr['failure'] = train_binary_classifier(df.drop(columns=['weighted']), final_y.apply(lambda x: x == 0))\n",
    "    df_corr['pass'] = train_binary_classifier(df.drop(columns=['weighted']), final_y.apply(lambda x: x == 1))\n",
    "\n",
    "    merged_input_features = pd.concat([df_corr, pd.DataFrame(final_df_features)], axis=1)\n",
    "\n",
    "    y_one_hot = pd.get_dummies(final_y)\n",
    "\n",
    "    def create_model(input_shape):\n",
    "        model = Sequential([\n",
    "            InputLayer(shape=(input_shape,)),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(3, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    n_splits = 5\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "\n",
    "    for fold_no, (train, test) in enumerate(kfold.split(merged_input_features, y_one_hot), 1):\n",
    "        model = create_model(merged_input_features.shape[1])\n",
    "        \n",
    "        history = model.fit(\n",
    "            merged_input_features.iloc[train], \n",
    "            y_one_hot.iloc[train], \n",
    "            epochs=30, \n",
    "            batch_size=32, \n",
    "            validation_data=(merged_input_features.iloc[test], y_one_hot.iloc[test]),\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        scores = model.evaluate(merged_input_features.iloc[test], y_one_hot.iloc[test], verbose=0)\n",
    "        print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "        \n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, len(acc_per_fold)):\n",
    "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "    final_model = create_model(merged_input_features.shape[1])\n",
    "    final_model.fit(merged_input_features, y_one_hot, epochs=30, batch_size=32, verbose=0)\n",
    "\n",
    "    return final_model, merged_input_features\n",
    "\n",
    "# Example usage:\n",
    "# model, features = run_analysis([5, 6, 7])  # Replace with your desired tag IDs"
   ],
   "id": "5fa1874927128866",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:17:20.357074Z",
     "start_time": "2024-08-02T05:17:20.355357Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8f77daa3ac439f04",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:17:20.503846Z",
     "start_time": "2024-08-02T05:17:20.493111Z"
    }
   },
   "cell_type": "code",
   "source": "merged_input_features",
   "id": "cc6da281204fc63e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          success   failure          pass    0    1    2    3    4    5    6  \\\n",
       "0    1.210673e-09  0.757611  9.992988e-01  4.0  4.0  5.0  3.0  5.0  4.0  6.0   \n",
       "1    5.100537e-10  0.000065  2.185780e-08  5.0  6.0  7.0  1.0  5.0  6.0  5.0   \n",
       "2    9.249924e-18  0.012181  3.329029e-02  2.0  5.0  6.0  4.0  1.0  2.0  7.0   \n",
       "3    3.563413e-20  0.204300  1.163027e-02  5.0  6.0  5.0  4.0  7.0  6.0  6.0   \n",
       "4    1.651953e-19  0.999433  9.994544e-01  6.0  4.0  3.0  1.0  4.0  2.0  7.0   \n",
       "..            ...       ...           ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "473  2.493636e-22  0.742487  9.963731e-01  4.0  4.0  4.0  4.0  3.0  2.0  7.0   \n",
       "474  3.318062e-19  0.006182  6.388703e-03  5.0  4.0  5.0  9.0  5.0  5.0  6.0   \n",
       "475  2.226829e-16  0.045137  3.432620e-03  5.0  4.0  6.0  2.0  3.0  5.0  4.0   \n",
       "476  5.163840e-25  0.008712  1.506115e-02  5.0  3.0  5.0  7.0  4.0  6.0  3.0   \n",
       "477  1.539102e-21  0.188550  7.471893e-02  7.0  3.0  6.0  3.0  7.0  5.0  5.0   \n",
       "\n",
       "     ...   19   20   21   22   23   24   25   26   27   28  \n",
       "0    ...  4.0  5.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1    ...  3.0  6.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "2    ...  4.0  7.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3    ...  4.0  6.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "4    ...  1.0  6.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "473  ...  4.0  7.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "474  ...  8.0  7.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "475  ...  3.0  5.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "476  ...  7.0  5.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "477  ...  4.0  5.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[478 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success</th>\n",
       "      <th>failure</th>\n",
       "      <th>pass</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.210673e-09</td>\n",
       "      <td>0.757611</td>\n",
       "      <td>9.992988e-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.100537e-10</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>2.185780e-08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.249924e-18</td>\n",
       "      <td>0.012181</td>\n",
       "      <td>3.329029e-02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.563413e-20</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>1.163027e-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.651953e-19</td>\n",
       "      <td>0.999433</td>\n",
       "      <td>9.994544e-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2.493636e-22</td>\n",
       "      <td>0.742487</td>\n",
       "      <td>9.963731e-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>3.318062e-19</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>6.388703e-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2.226829e-16</td>\n",
       "      <td>0.045137</td>\n",
       "      <td>3.432620e-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>5.163840e-25</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>1.506115e-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1.539102e-21</td>\n",
       "      <td>0.188550</td>\n",
       "      <td>7.471893e-02</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:17:20.655391Z",
     "start_time": "2024-08-02T05:17:20.648654Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "2de263e9715b7c13",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      weighted  attr_A  attr_B  attr_C  attr_E  attr_F  attr_H  attr_G  \\\n",
       "0     0.000000       4       4       5       3       5       4       6   \n",
       "1    60.000002       5       6       7       1       5       6       5   \n",
       "2    57.499999       2       5       6       4       1       2       7   \n",
       "3    64.999998       5       6       5       4       7       6       6   \n",
       "4     0.000000       6       4       3       1       4       2       7   \n",
       "..         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "473   0.000000       4       4       4       4       3       2       7   \n",
       "474  61.811566       5       4       5       9       5       5       6   \n",
       "475  56.534958       5       4       6       2       3       5       4   \n",
       "476  77.499998       5       3       5       7       4       6       3   \n",
       "477  49.845755       7       3       6       3       7       5       5   \n",
       "\n",
       "     attr_I  attr_L  ...  attr_IN  attr_SC  course_bscs  course_bsit  cfit_A  \\\n",
       "0         5       7  ...        4        5            1            0   False   \n",
       "1         7       5  ...        3        6            1            0   False   \n",
       "2         4       7  ...        4        7            1            0    True   \n",
       "3         7       9  ...        4        6            1            0   False   \n",
       "4         8       5  ...        1        6            1            0   False   \n",
       "..      ...     ...  ...      ...      ...          ...          ...     ...   \n",
       "473       7       9  ...        4        7            0            1   False   \n",
       "474       5       8  ...        8        7            0            1   False   \n",
       "475       5       7  ...        3        5            0            1   False   \n",
       "476       3       7  ...        7        5            0            1    True   \n",
       "477       7       4  ...        4        5            0            1   False   \n",
       "\n",
       "     cfit_AA  cfit_BA  cfit_H  cfit_L  cfit_M  \n",
       "0      False    False   False    True   False  \n",
       "1       True    False   False   False   False  \n",
       "2      False    False   False   False   False  \n",
       "3       True    False   False   False   False  \n",
       "4      False     True   False   False   False  \n",
       "..       ...      ...     ...     ...     ...  \n",
       "473    False    False   False    True   False  \n",
       "474    False    False    True   False   False  \n",
       "475    False    False   False    True   False  \n",
       "476    False    False   False   False   False  \n",
       "477    False    False   False    True   False  \n",
       "\n",
       "[478 rows x 30 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted</th>\n",
       "      <th>attr_A</th>\n",
       "      <th>attr_B</th>\n",
       "      <th>attr_C</th>\n",
       "      <th>attr_E</th>\n",
       "      <th>attr_F</th>\n",
       "      <th>attr_H</th>\n",
       "      <th>attr_G</th>\n",
       "      <th>attr_I</th>\n",
       "      <th>attr_L</th>\n",
       "      <th>...</th>\n",
       "      <th>attr_IN</th>\n",
       "      <th>attr_SC</th>\n",
       "      <th>course_bscs</th>\n",
       "      <th>course_bsit</th>\n",
       "      <th>cfit_A</th>\n",
       "      <th>cfit_AA</th>\n",
       "      <th>cfit_BA</th>\n",
       "      <th>cfit_H</th>\n",
       "      <th>cfit_L</th>\n",
       "      <th>cfit_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.000002</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.499999</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.999998</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>61.811566</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>56.534958</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>77.499998</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>49.845755</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 30 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:17:20.822489Z",
     "start_time": "2024-08-02T05:17:20.819062Z"
    }
   },
   "cell_type": "code",
   "source": "y_one_hot",
   "id": "e2c9e0f27cb19839",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         0      1      2\n",
       "0     True  False  False\n",
       "1    False   True  False\n",
       "2    False   True  False\n",
       "3    False   True  False\n",
       "4     True  False  False\n",
       "..     ...    ...    ...\n",
       "473   True  False  False\n",
       "474  False   True  False\n",
       "475  False   True  False\n",
       "476  False   True  False\n",
       "477   True  False  False\n",
       "\n",
       "[478 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:17:20.989242Z",
     "start_time": "2024-08-02T05:17:20.915795Z"
    }
   },
   "cell_type": "code",
   "source": "final_model.predict(merged_input_features)",
   "id": "5a69443cb4caf07d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.5701861e-01, 4.2186756e-02, 7.9461688e-04],\n",
       "       [3.4556751e-07, 9.9999964e-01, 1.9087590e-08],\n",
       "       [2.3443113e-07, 9.9999976e-01, 5.2051754e-09],\n",
       "       ...,\n",
       "       [6.1188825e-06, 9.9999356e-01, 3.8790984e-07],\n",
       "       [1.9204290e-06, 9.9999809e-01, 4.3936126e-08],\n",
       "       [1.0541964e-01, 8.9349461e-01, 1.0858263e-03]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T05:17:21.417262Z",
     "start_time": "2024-08-02T05:17:21.415282Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e71a0e4a9e87a160",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "447f541f0126bddd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
